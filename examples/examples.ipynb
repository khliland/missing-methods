{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d7c1f2",
   "metadata": {},
   "source": [
    "# Examples\n",
    "This notebook runs every doctest snippet that appears in the package docstrings, so you can verify the NA-aware helpers interactively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883958cb",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- Principal Component Analysis (PCA)\n",
    "- Multiple Factor Analysis (MFA)\n",
    "- Partial Least Squares (PLS)\n",
    "- RV coefficient\n",
    "    - RV/RV2\n",
    "    - RV/RV2 with list of arrays\n",
    "- Normalization\n",
    "- Standardization\n",
    "- scikit-learn style\n",
    "    - PCA\n",
    "    - PLSRegressor\n",
    "    - Normalizer\n",
    "    - StandardScaler\n",
    "    - scikit-learn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39663616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from missing_methods import pca, pls, rv, rv2, rv_list, rv2_list, mfa\n",
    "from missing_methods.sk import PCA, PLSRegressor, Normalizer, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b64a86",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "This cell runs `missing_methods.pca`, a NIPALS-based decomposition that scales inner products by observed proportions so NaNs are ignored during the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2bc74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2.5, 2.4],\n",
    "              [0.5, 0.7],\n",
    "              [2.2, 2.9]])\n",
    "X[1, 0] = np.nan\n",
    "result = pca(X, ncomp=2)\n",
    "result[\"scores\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd07889",
   "metadata": {},
   "source": [
    "## Multiple Factor Analysis (MFA)\n",
    "`missing_methods.mfa` scales each block by its leading NIPALS eigenvalue before concatenating, ensuring NaNs stay handled via the MCAR-scaled PCA at every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e0394e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "X = rng.standard_normal((10, 4))\n",
    "Y = rng.standard_normal((10, 4)) + 0.3 * X\n",
    "Z = rng.standard_normal((10, 4)) + 0.2 * X\n",
    "X[[1, 3, 7], 2] = np.nan\n",
    "Y[[0, 4, 9], 1] = np.nan\n",
    "Z[[5, 6], 0] = np.nan\n",
    "blocks = [X, Y, Z]\n",
    "result = mfa(blocks, ncomp=3)\n",
    "result[\"scores\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c432e",
   "metadata": {},
   "source": [
    "## Partial Least Squares (PLS)\n",
    "`missing_methods.pls` alternates NIPALS updates between X and Y, scaling cross-products by the observed entries so NaNs do not distort the latent components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e4b469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2.5, 2.4],\n",
    "              [0.5, 0.7],\n",
    "              [2.2, 2.9]])\n",
    "Y = np.array([[2.4],\n",
    "              [0.6],\n",
    "              [2.1]])\n",
    "X[1, 0] = np.nan\n",
    "Y[2, 0] = np.nan\n",
    "result = pls(X, Y, ncomp=2)\n",
    "result[\"scores\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6166914",
   "metadata": {},
   "source": [
    "## RV coefficient\n",
    "`missing_methods.rv` uses NIPALS PCA outputs to compute RV coefficients with MCAR-scaled inner products so NaNs are excluded from the similarity sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d95b5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7327404890152707"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2.5, 2.4],\n",
    "              [0.5, 0.7],\n",
    "              [2.2, 2.9]])\n",
    "Y = np.array([[2.4, 2.9],\n",
    "              [0.6, 0.5],\n",
    "              [2.1, 2.2]])\n",
    "X[1, 0] = np.nan\n",
    "Y[2, 0] = np.nan\n",
    "rv_value = float(rv(X, Y))\n",
    "rv_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368579f",
   "metadata": {},
   "source": [
    "## RV2 coefficient\n",
    "`missing_methods.rv2` zeroes each Gram diagonal before computing the cosine-like similarity, and its NIPALS-based scores ignore NaNs thanks to scaled inner products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f967657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6730600493101697"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2.5, 2.4],\n",
    "              [0.5, 0.7],\n",
    "              [2.2, 2.9]])\n",
    "Y = np.array([[2.4, 2.9],\n",
    "              [0.6, 0.5],\n",
    "              [2.1, 2.2]])\n",
    "X[1, 0] = np.nan\n",
    "Y[2, 0] = np.nan\n",
    "rv2_value = float(rv2(X, Y))\n",
    "rv2_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79941c8e",
   "metadata": {},
   "source": [
    "## RV with list of arrays\n",
    "`missing_methods.rv_list` reuses the NIPALS-driven rv helper to build a symmetric matrix, preserving the NaN-aware scaling in every entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53031254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2.5, 2.4],\n",
    "              [0.5, 0.7],\n",
    "              [2.2, 2.9]])\n",
    "Y = np.array([[2.4, 2.9],\n",
    "              [0.6, 0.5],\n",
    "              [2.1, 2.2]]) + 0.3 * X\n",
    "Z = np.array([[1.2, 0.9],\n",
    "              [0.3, 0.4],\n",
    "              [1.1, 1.3]]) + 0.2 * X\n",
    "X[1, 0] = np.nan\n",
    "Y[2, 0] = np.nan\n",
    "Z[0, 1] = np.nan\n",
    "arrays = [X, Y, Z]\n",
    "rv_list(arrays).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a070c2",
   "metadata": {},
   "source": [
    "## RV2 with list of arrays\n",
    "`missing_methods.rv2_list` calls rv2 for each pair, so every element shares the NIPALS-based, MCAR-scaled diagonal removal that keeps NaNs silent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceea2340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2.5, 2.4],\n",
    "              [0.5, 0.7],\n",
    "              [2.2, 2.9]])\n",
    "Y = np.array([[2.4, 2.9],\n",
    "              [0.6, 0.5],\n",
    "              [2.1, 2.2]]) + 0.3 * X\n",
    "Z = np.array([[1.2, 0.9],\n",
    "              [0.3, 0.4],\n",
    "              [1.1, 1.3]]) + 0.2 * X\n",
    "X[1, 0] = np.nan\n",
    "Y[2, 0] = np.nan\n",
    "Z[0, 1] = np.nan\n",
    "arrays = [X, Y, Z]\n",
    "rv2_list(arrays).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82075772",
   "metadata": {},
   "source": [
    "## Normalize helper\n",
    "`missing_methods.normalize` scales each column by the MCAR-aware norms, so NaNs never inflate the length before ignoring them in the NIPALS-backed rescaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c396e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from missing_methods import normalize\n",
    "X = np.array([[3.0, np.nan], [0.0, 4.0]])\n",
    "normalized = normalize(X)\n",
    "normalized.shape\n",
    "float(np.nanmax(normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba62b2ef",
   "metadata": {},
   "source": [
    "## Standardize helper\n",
    "`missing_methods.standardize` centers each column via MCAR-aware means and scales by NaN-safe sums of squares, so inverse transforms stay consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b09d128c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from missing_methods import standardize\n",
    "X = np.array([[1.0, 2.0], [np.nan, 4.0]])\n",
    "standardized = standardize(X)\n",
    "np.nanmean(standardized, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934320cf",
   "metadata": {},
   "source": [
    "## PCA in scikit-learn style\n",
    "The sklearn PCA layers on the NIPALS-based helper, alternating X updates and scaling cross-products only where data is observed so NaNs stay excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a2d249e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2.5, 2.4],\n",
    "              [0.5, 0.7],\n",
    "              [2.2, 2.9]])\n",
    "X[1, 0] = np.nan\n",
    "estimator = PCA(ncomp=2)\n",
    "estimator.fit(X)\n",
    "estimator.transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc60927",
   "metadata": {},
   "source": [
    "## PLSRegressor in scikit-learn style\n",
    "The sklearn PLSRegressor layers on the NIPALS-based helper, alternating X/Y updates and scaling cross-products only where data is observed so NaNs stay excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4fbf288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2.5, 2.4],\n",
    "              [0.5, 0.7],\n",
    "              [2.2, 2.9]])\n",
    "Y = np.array([[2.4],\n",
    "              [0.6],\n",
    "              [2.1]])\n",
    "X[2, 1] = np.nan\n",
    "Y[0, 0] = np.nan\n",
    "estimator = PLSRegressor(ncomp=2)\n",
    "estimator.fit(X, Y)\n",
    "estimator.predict(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c684f0",
   "metadata": {},
   "source": [
    "## Normalizer in scikit-learn style\n",
    "The sklearn Normalizer wraps `_normalize`, a NIPALS-based l2 rescaler that divides only by norms computed over observed entries so NaNs never contribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d34c7408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[3.0, np.nan],\n",
    "              [0.0, 4.0]])\n",
    "normalizer = Normalizer()\n",
    "normalized = normalizer.fit_transform(X)\n",
    "normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afebc439",
   "metadata": {},
   "source": [
    "## StandardScaler in scikit-learn style\n",
    "StandardScaler inherits the MCAR-aware NIPALS variance estimates so transform/inverse_transform scale only via NaN-safe sums of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5cfde25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1.0, 2.0],\n",
    "              [np.nan, 4.0]])\n",
    "scaler = StandardScaler()\n",
    "transformed = scaler.fit_transform(X)\n",
    "reconstructed = scaler.inverse_transform(transformed)\n",
    "np.allclose(reconstructed, X, equal_nan=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edfc06",
   "metadata": {},
   "source": [
    "## scikit-learn pipeline\n",
    "NaN-safe StandardScaler and PLSRegressor combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce7c55c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "X = np.array([[2.5, 2.4],\n",
    "              [0.5, 0.7],\n",
    "              [2.2, 2.9]])\n",
    "Y = np.array([[2.4],\n",
    "              [0.6],\n",
    "              [2.1]])\n",
    "X[2, 1] = np.nan\n",
    "Y[0, 0] = np.nan\n",
    "scaler = StandardScaler()\n",
    "estimator = PLSRegressor(ncomp=2)\n",
    "pipeline = make_pipeline(scaler, estimator)\n",
    "pipeline.fit(X, Y)\n",
    "pipeline.predict(X).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ind320_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
